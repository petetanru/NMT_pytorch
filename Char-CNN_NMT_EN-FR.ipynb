{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose and dataset\n",
    "This page is mainly for model development. I use a dataset created by Udacity for translating EN -> FR. 120k samples altogether with merely 300-400 unique vocabs per language. A working model should be able to get at least 95% very quickly. With the current minimal configuration, this model achieves around 97.5% validation accuracy.\n",
    "\n",
    "The following code is a basic implementation of https://arxiv.org/abs/1610.03017 and we will not be using any tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from pad1d import pad1d\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "cudafloat = torch.cuda.FloatTensor\n",
    "cudalong = torch.cuda.LongTensor\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab2(file1, src):\n",
    "    # tweaked version of: https://github.com/nyu-dl/dl4mt-c2c/blob/master/preprocess/build_dictionary_char.py\n",
    "    # TODO: figure out why the original function omit characters like Ãƒ.\n",
    "    \n",
    "    word_dict = {}\n",
    "    master_set = set('0')\n",
    "    for sample in file1:\n",
    "        set_letter = set(sample)\n",
    "        master_set = master_set.union(set_letter)\n",
    "    \n",
    "    if src:\n",
    "    # 0 -> ZERO\n",
    "    # 1 -> UNK\n",
    "    # 2 -> SOS\n",
    "    # 3 -> EOS\n",
    "        tokens = \"ZERO UNK SOS EOS\".split()\n",
    "    else:\n",
    "        tokens = \"EOS UNK\".split()\n",
    "\n",
    "    for ii, aa in enumerate(tokens):\n",
    "        word_dict[aa] = ii\n",
    "\n",
    "    for ii, ww in enumerate(master_set):\n",
    "        word_dict[ww] = ii + len(tokens)\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_sentences = load_data('data/small_vocab_en')\n",
    "inp_dict = build_vocab2(english_sentences, True)\n",
    "\n",
    "french_sentences = load_data('data/small_vocab_fr')\n",
    "tgt_dict = build_vocab2(french_sentences, False)\n",
    "\n",
    "train_sz = int(len(english_sentences)*0.9)\n",
    "\n",
    "train_data = english_sentences[:train_sz]\n",
    "train_target = french_sentences[:train_sz]\n",
    "\n",
    "val_data = english_sentences[train_sz:]\n",
    "val_target = french_sentences[train_sz:]\n",
    "\n",
    "inp_sz = len(inp_dict)\n",
    "out_sz = len(tgt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_len_finder(data1, data2):\n",
    "    longest_sent = 0\n",
    "    for sentence in data1:\n",
    "        curr_len = len(sentence)\n",
    "        if curr_len > longest_sent:\n",
    "            longest_sent = curr_len\n",
    "    for sentence2 in data2:\n",
    "        curr_len = len(sentence2)\n",
    "        if curr_len > longest_sent:\n",
    "            longest_sent = curr_len\n",
    "    return longest_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ordering data by length decreases training time (since we vectorize only to max_len of the batch), but really hurts performance.\n",
    "# There seems to be some serious lashback to not mixing up data. \n",
    "# This is in contrast to how humans learn though, we start from something easier and shorter first, then build on. \n",
    "\n",
    "\n",
    "# def sort_data_len(data, target): \n",
    "#     len_order = []\n",
    "#     for i in range(len(data)):\n",
    "#         len_data = len(data[i])\n",
    "#         len_target = len(target[i])\n",
    "#         max_len = max((len_data, len_target))\n",
    "#         len_order.append(max_len)\n",
    "\n",
    "#     # simple version\n",
    "#     three_list = sorted(zip(len_order, data, target))\n",
    "\n",
    "#     train_data = [x for l,x,y in three_list]\n",
    "#     train_target = [y for l,x,y in three_list]\n",
    "    \n",
    "#     return train_data, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = 2000\n",
    "print(train_data[z])\n",
    "print(train_target[z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# def preprocess(x, y, length):\n",
    "#     x_padded = pad_sequences(x, maxlen=length, padding='post')\n",
    "#     y_padded = pad_sequences(y, maxlen=length, padding='post')\n",
    "#     return x_padded, y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad1d(tensor, pad, permute_dims=True):\n",
    "    # source: https://github.com/pytorch/pytorch/issues/2637\n",
    "    # tensor should be in shape (batch, time, feat)\n",
    "    # pad should be in shape (left, right)\n",
    "    if permute_dims:\n",
    "        tensor = tensor.permute(0, 2, 1).contiguous() # get features on first dim since we are padding time\n",
    "    else:\n",
    "        tenosr = tensor.contiguous()\n",
    "    original_size = tensor.size() # (batch, feat, time)\n",
    "    final_new_size = (original_size[0], original_size[1], original_size[2] + pad[0] + pad[1])\n",
    "    temp_new_size = original_size[:2] + (1,) + original_size[2:]\n",
    "    assert len(temp_new_size) == 4\n",
    "    tensor = tensor.view(*temp_new_size)\n",
    "    pad = pad + (0, 0)\n",
    "    tensor = F.pad(tensor, pad)\n",
    "    tensor = tensor.view(*final_new_size)\n",
    "    if permute_dims:\n",
    "        tensor = tensor.permute(0, 2, 1)\n",
    "    return tensor\n",
    "\n",
    "def train_vectorize(x, y):\n",
    "    seq_len = seq_len_finder(x, y)\n",
    "#     x, y = preprocess(x, y, seq_len)\n",
    "    Xtensor = torch.zeros(len(x), seq_len+1).long()\n",
    "    ytensor = torch.zeros(len(x), seq_len+1).long()\n",
    "    for i, seq in enumerate(x):\n",
    "        for t, char in enumerate(seq):\n",
    "            Xtensor[i, t] = inp_dict[seq[t]]\n",
    "        Xtensor[i, len(seq)] = inp_dict['EOS']\n",
    "    for i_y, seq_y in enumerate(y):\n",
    "        for t_y, char_y in enumerate(seq_y):\n",
    "            ytensor[i_y, t_y] = tgt_dict[seq_y[t_y]]\n",
    "    return Xtensor, ytensor, seq_len\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    # Frees up variable from old graph. Variables\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data)\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim, N, dropout, k_num, k_size, poolstride,\n",
    "                 en_bi, en_layers, en_H,\n",
    "                 num_embed=inp_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.Ci = embed_dim\n",
    "        self.k_num = k_num  # channel-out (number of filters)\n",
    "        self.ks = zip(k_num, k_size)\n",
    "        self.k_sum = sum(k_num)\n",
    "        self.poolstride = poolstride\n",
    "        self.bi = 2 if en_bi == True else 1\n",
    "        self.en_H = en_H\n",
    "        self.N = N\n",
    "\n",
    "        self.embed = nn.Embedding(num_embed, embed_dim)\n",
    "\n",
    "        self.convks = nn.ModuleList()\n",
    "        for (num, size) in self.ks:\n",
    "            # half convolution padding with two sided W-1 to get same input and output length\n",
    "            self.convks.append(nn.Conv1d(in_channels=self.Ci,\n",
    "                                         out_channels=num,\n",
    "                                         kernel_size=size,\n",
    "                                         stride=1))\n",
    "        self.biGRU = nn.LSTM(input_size=self.k_sum,\n",
    "                            hidden_size=en_H,\n",
    "                            num_layers=en_layers,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=en_bi)\n",
    "        self.gate = nn.Linear(self.k_sum, self.k_sum)\n",
    "        self.highway1 = nn.Linear(self.k_sum, self.k_sum)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.logsoftmax = nn.LogSoftmax()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(en_layers * self.bi, self.N, en_H).type(cudafloat))\n",
    "        c0 = Variable(torch.zeros(en_layers * self.bi, self.N, en_H).type(cudafloat))\n",
    "        return h0, c0\n",
    "\n",
    "    def pad_conv_and_pool(self, x, conv):\n",
    "        # padding for half convolution (aka 'same' padding), which needs asymetric padding\n",
    "        # asymmetric padding assumes front pad is longer. k_size=4 would have 2 zeros padded front and 1 zero padded back\n",
    "        # pad1d takes (N,W,D)\n",
    "        k_size = conv.kernel_size[0]\n",
    "        if k_size > 1:\n",
    "            total_pad = k_size - 1\n",
    "            pad_front = math.ceil(total_pad / 2)\n",
    "            pad_back = total_pad - pad_front\n",
    "            x = pad1d(x, (pad_front, pad_back))\n",
    "        x = F.relu(conv(x.transpose(1, 2)))  # (N,W,Ci) => (N,Co,W)\n",
    "        result = F.max_pool1d(x, kernel_size=self.poolstride)  # (N, Co, W/s)\n",
    "        return result\n",
    "    \n",
    "    def highway(self, x):\n",
    "        x.contiguous()\n",
    "        gate = F.sigmoid(self.gate(x.view(-1, self.k_sum)))\n",
    "        high1 = gate * F.relu(self.highway1(x.view(-1, self.k_sum)))\n",
    "        high2 = (1-gate)*x\n",
    "        result = high1 + high2\n",
    "        return result\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input - (N,W)\n",
    "        x = self.embed(input)  # (N,W,D)\n",
    "        x = [self.pad_conv_and_pool(x, convk) for convk in self.convks]  # (N,Ci,W) => (N,Co,W/s)\n",
    "        x = torch.cat(x, dim=1)  # (N, sum(Co) for all k_width, W/s)\n",
    "        x = x.permute(2, 0, 1)  # (W/s,N,D=k_sum) prep for rnn\n",
    "        x = self.highway(x)\n",
    "        output, hidden = self.biGRU(x.view(-1, self.N, self.k_sum), hidden)  # (W/s,N,H*bi)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luong Attention (process new input as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class LuongDecoder(nn.Module):\n",
    "    def __init__(self, de_H, en_Hbi, de_layers, dropout, de_bi, N, de_embed, out_sz=out_sz):\n",
    "        super(LuongDecoder, self).__init__()\n",
    "        self.bi = 2 if de_bi == True else 1\n",
    "        self.de_H = de_H\n",
    "        self.en_Hbi = en_Hbi\n",
    "        self.de_Hbi = self.bi * self.de_H\n",
    "        self.de_layers = de_layers\n",
    "        self.embed_sz = de_embed\n",
    "        self.N = N\n",
    "        self.out_sz = out_sz\n",
    "\n",
    "        self.embedding = nn.Embedding(out_sz, de_embed)\n",
    "        self.gru = nn.LSTM(input_size=de_embed,\n",
    "                          hidden_size=de_H,\n",
    "                          num_layers=de_layers,\n",
    "                          dropout=dropout,\n",
    "                          bidirectional=de_bi)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.logsoftmax = nn.LogSoftmax()\n",
    "\n",
    "        # attention (Luong)\n",
    "        # TODO: revise, won't work for all cases\n",
    "        self.score_lin = nn.Linear(self.de_Hbi, self.de_Hbi * self.de_layers)\n",
    "        self.lin_comb = nn.Linear(self.de_Hbi + self.en_Hbi, self.de_Hbi)\n",
    "        self.lin_out = nn.Linear(self.de_Hbi, self.out_sz)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(self.de_layers * self.bi, N, self.de_H).type(cudafloat))\n",
    "        h=c0 = Variable(torch.zeros(self.de_layers * self.bi, N, self.de_H).type(cudafloat))\n",
    "        return h0, c0\n",
    "\n",
    "    def forward(self, inputs, encoder_out, hidden):\n",
    "        W_s, _, _ = encoder_out.size()\n",
    "\n",
    "        # decoder RNN's output\n",
    "        embed = self.embedding(inputs.transpose(0, 1))  # (N,W) => (W,N,D)\n",
    "        W_t, _, _ = embed.size()\n",
    "\n",
    "        # print(\"rnn input\")\n",
    "        # print(embed.size(), hidden.size())\n",
    "        rnn_output, hidden = self.gru(embed, hidden)  # (W,N,D) => output (W,N,H*bi), hidden (layer*bi, N, H)\n",
    "\n",
    "        rnn_output = rnn_output.transpose(0, 1)  # (N,W,H)\n",
    "        rnn_output.contiguous()  # makes a contiguous copy for view\n",
    "\n",
    "        # source hidden state\n",
    "        # tensor containing the output features (h_s) from the last layer of the encoder RNN\n",
    "        encoder_out = encoder_out.transpose(0, 1)  # (W,N,H) => (N,W,H)\n",
    "        encoder_out.contiguous()  # (N,W,H)\n",
    "\n",
    "        ### Luong's attn output & score\n",
    "\n",
    "        # linear on RNN output\n",
    "        h_t = self.score_lin(rnn_output.view(-1, self.de_Hbi))  # (N*W,H) dot (H,H)\n",
    "        h_t = h_t.view(self.N, -1, self.de_Hbi)  # (N*W,H) => (N,W,H)\n",
    "        h_s = encoder_out.permute(0, 2, 1)  # (N,W,H) => (N,H,W)\n",
    "\n",
    "        # Matrix multiply between RNN output and Encoder's output\n",
    "        scores = torch.bmm(h_t, h_s)  # (N,W_t,H) dot (N,H,W_s) => (N, W_t, W_s)\n",
    "\n",
    "        # Normalize with softmax\n",
    "        align_vec = F.softmax(scores.view(-1, W_s))  # softmax(N*W_t, Ws)\n",
    "        align_vec = align_vec.view(self.N, -1, W_s)  # (N,W_t,W_s)\n",
    "\n",
    "        # context_vec as weighted avg. of source states, based on attn weights\n",
    "        context_vec = torch.bmm(align_vec, encoder_out)  # (N,W_t,W_s) dot (N,W_s,H_en) => (N,W_t,H_en)\n",
    "        concat_vec = torch.cat((context_vec, rnn_output), dim=2)  # (N,W_t,H_cat)\n",
    "        concat_vec = concat_vec.view(-1, concat_vec.size()[2])  # (N,W_t,H_cat) => (N*W_t, H_cat)\n",
    "\n",
    "        # linear, tanh\n",
    "        attn_h = self.lin_comb(concat_vec)  # (N*W_t, H*2) => (N*W_t,H)\n",
    "        attn_h = attn_h.view(self.N, W_t, self.de_Hbi)  # (N,W_t,H)\n",
    "        attn_h = F.tanh(attn_h.transpose(0, 1))  # (W_t,N,H)\n",
    "\n",
    "        # Linear, softmax\n",
    "        # output = self.dropout(attn_h)\n",
    "        output = attn_h\n",
    "        output = self.lin_out(output.view(-1, self.de_Hbi))  # (W,N,H) => (W*N,H)\n",
    "        output = self.logsoftmax(output)  # (W*N,H) => (W*N,Out)\n",
    "        output = output.view(W_t, self.N, self.out_sz)  # (W*N,Out) => (W,N,Out)\n",
    "\n",
    "        return output, hidden, align_vec.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "dropout = 0.2\n",
    "\n",
    "''' Encoder config '''\n",
    "embed_dim = 256\n",
    "N = 128\n",
    "poolstride = 5\n",
    "en_bi = True\n",
    "en_layers = 1\n",
    "en_H = 256\n",
    "k_num = [200, 200, 250, 250, 300, 300, 300, 300]\n",
    "k_size = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "''' Decoder config '''\n",
    "de_embed = 256\n",
    "de_H = 256\n",
    "de_layers = 1\n",
    "de_bi = True\n",
    "en_Hbi = en_H * (2 if en_bi == True else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(embed_dim=embed_dim, N=N, dropout=dropout, k_num=k_num, k_size=k_size, poolstride=poolstride,\n",
    "                      en_bi=en_bi, en_layers=en_layers, en_H=en_H)\n",
    "decoder = LuongDecoder(de_embed=de_embed, de_H=de_H, en_Hbi=en_Hbi, de_layers=de_layers, dropout=dropout, de_bi=de_bi, N=N)\n",
    "decoder.cuda()\n",
    "encoder.cuda()\n",
    "en_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "de_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_train, graph_val = [], []\n",
    "best_val_loss = 100.0\n",
    "best_val_acc = 0.0\n",
    "n_epochs = 40\n",
    "train_remainder = len(train_data) % N\n",
    "val_remainder = len(val_data) % N\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    total_val_len = 0\n",
    "    en_hidden = encoder.init_hidden()\n",
    "    de_hidden = decoder.init_hidden()\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for batch in range(0, len(train_data) - train_remainder,N):\n",
    "        loss = 0\n",
    "        data_raw = train_data[batch:batch+N]\n",
    "        target_raw = train_target[batch:batch+N]\n",
    "        data, target, max_len = train_vectorize(data_raw, target_raw)\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        en_hidden = repackage_hidden(en_hidden)\n",
    "        de_hidden = repackage_hidden(de_hidden)\n",
    "\n",
    "        # forward, backward, optimize\n",
    "        en_out, en_hidden = encoder(data, en_hidden)\n",
    "        de_hidden = en_hidden\n",
    "        de_in = Variable(torch.zeros(decoder.N, 1).type(cudalong))\n",
    "        \n",
    "        for di in range(max_len):\n",
    "            de_out, de_hidden, attn = decoder(de_in, en_out, de_hidden)  # (W=1,N,Out)\n",
    "            de_out = de_out.squeeze(0)  # (N, Out)\n",
    "            target_T = target.transpose(0, 1)  # (N,W) => (W, N)\n",
    "            loss += criterion(de_out, target_T[di])  # (N,Out) and (N)\n",
    "            \n",
    "            train_loss += loss.data[0]/max_len\n",
    "            de_in = target_T[di].unsqueeze(1)\n",
    "\n",
    "        en_optimizer.zero_grad()\n",
    "        de_optimizer.zero_grad()\n",
    "        loss.backward(retain_variables=True)\n",
    "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 5)\n",
    "        torch.nn.utils.clip_grad_norm(decoder.parameters(), 5)\n",
    "        en_optimizer.step()\n",
    "        de_optimizer.step()\n",
    "        \n",
    "        if batch%(N*100) == 0:\n",
    "            print (\"update\", batch/N, time.time() - start_time)\n",
    "\n",
    "    # evaluate with validation set\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    for batch in range(0, len(val_data) - val_remainder, N):\n",
    "        data_raw = val_data[batch:batch + N]\n",
    "        target_raw = val_target[batch:batch + N]\n",
    "        data, target, max_len = train_vectorize(data_raw, target_raw)\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target, volatile=True)\n",
    "        en_hidden = repackage_hidden(en_hidden)\n",
    "        de_hidden = repackage_hidden(de_hidden)\n",
    "\n",
    "        en_out, en_hidden = encoder(data, en_hidden)\n",
    "        de_hidden = en_hidden\n",
    "        de_in = Variable(torch.zeros(decoder.N, 1).type(cudalong))\n",
    "\n",
    "        for di in range(max_len):\n",
    "            de_out, de_hidden, attn = decoder(de_in, en_out, de_hidden)  # (W=1,N,Out)\n",
    "            de_out = de_out.squeeze(0)  # (N, Out)\n",
    "            target_T = target.transpose(0, 1)  # (N,W) => (W, N)\n",
    "            loss = criterion(de_out, target_T[di])  # (N,Out) and (N)\n",
    "            val_loss += loss.data[0]/(max_len)\n",
    "\n",
    "            de_in = Variable(de_out.data.max(1)[1].type(cudalong), volatile=True)\n",
    "\n",
    "            pred = de_out.data.max(1)[1].squeeze().contiguous()  # get the index of the max log-probability\n",
    "            target_pred = target_T[di].contiguous()\n",
    "            correct += pred.eq(target_pred.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "        total_val_len += max_len\n",
    "        \n",
    "    train_loss /= len(train_data)\n",
    "    val_loss /= len(val_data)\n",
    "\n",
    "    graph_train.append(train_loss)\n",
    "    graph_val.append(val_loss)\n",
    "\n",
    "    print('[%d] train loss: %.3f val loss: %.4f acc: %.3f time: %.3f' % \\\n",
    "          (epoch + 1, train_loss, val_loss, correct / (total_val_len*N),\n",
    "           time.time() - start_time))\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(encoder.state_dict(), 'best_encoder_weight_en-fr')\n",
    "        torch.save(decoder.state_dict(), 'best_decoder_weight_en-fr')\n",
    "        \n",
    "        print('saving least val loss model from epoch [%d]'% (epoch+1))\n",
    "        print(val_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.ylabel('Avg. loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(graph_train)\n",
    "plt.plot(graph_val)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out translation\n",
    "Here, I reinitialize the model with batch size of 1 and load the weights. You can try different english output to see what the model translates as. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def toy_vectorize2(x):\n",
    "    seq_len = len(x)\n",
    "    Xtensor = torch.zeros(1, seq_len+1).long()\n",
    "    for t, char in enumerate(x):\n",
    "        Xtensor[0, t] = inp_dict[x[t]]\n",
    "    Xtensor[0, seq_len] = inp_dict['EOS']\n",
    "    return Xtensor\n",
    "\n",
    "tgt_dict_i2c = {v:k for k, v in tgt_dict.items()}\n",
    "N_toy = 1\n",
    "correct_toy = 0\n",
    "toy_data = val_data[3]\n",
    "print(\"input :\", toy_data)\n",
    "print(\"output :\")\n",
    "\n",
    "encoder_toy = Encoder(embed_dim=embed_dim, N=N_toy, dropout=dropout, k_num=k_num, k_size=k_size, poolstride=poolstride,\n",
    "                      en_bi=en_bi, en_layers=en_layers, en_H=en_H)\n",
    "decoder_toy = LuongDecoder(de_embed=de_embed, de_H=de_H, en_Hbi=en_Hbi, de_layers=de_layers, dropout=dropout, de_bi=de_bi, N=N_toy)\n",
    "\n",
    "encoder_toy.load_state_dict(torch.load('best_encoder_weight_en-fr'))\n",
    "decoder_toy.load_state_dict(torch.load('best_decoder_weight_en-fr'))\n",
    "\n",
    "encoder_toy.cuda()\n",
    "decoder_toy.cuda()\n",
    "encoder_toy.eval()\n",
    "decoder_toy.eval()\n",
    "\n",
    "en_hidden_toy, de_hidden_toy = encoder_toy.init_hidden(), decoder_toy.init_hidden()\n",
    "toy_data = toy_vectorize2(toy_data)\n",
    "toy_data = Variable(toy_data.cuda())\n",
    "\n",
    "toy_out, en_hidden_toy = encoder_toy(toy_data, en_hidden_toy)\n",
    "de_hidden_toy = en_hidden_toy\n",
    "\n",
    "de_in_toy = Variable(torch.zeros(decoder_toy.N, 1).type(cudalong))\n",
    "for di in range(100):\n",
    "    de_out, de_hidden_toy, attn = decoder_toy(de_in_toy, toy_out, de_hidden_toy)  # (W=1,N,Out)\n",
    "    de_out = de_out.squeeze(0)  # (N, Out)\n",
    "    \n",
    "    de_in_toy = Variable(de_out.data.max(1)[1].type(cudalong), volatile=True)\n",
    "    \n",
    "    output_dist = de_out.view(-1).exp().cpu()\n",
    "    top_i = torch.multinomial(output_dist, 1)[0]\n",
    "    pred_data = tgt_dict_i2c[top_i.data[0]]\n",
    "    \n",
    "    sys.stdout.write(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
